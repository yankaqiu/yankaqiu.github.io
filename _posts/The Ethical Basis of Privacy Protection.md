---
layout: post
title: The Ethical Basis of Privacy Protection
date: 2025-04-28 15:06:00
description: 
tags: privacy
categories: sample-posts
citation: true
---

# **The Ethical Basis of Privacy Protection**

It’s been three years, and every time I hear someone say, *“Haven’t we already lost our privacy? What’s the point of struggling anymore?”* I still need to take five seconds to suppress the urge to lecture for two hours.



First, the argument *“because privacy is already gone, privacy protection is no longer worth discussing”* is logically flawed. Whether privacy still exists cannot serve as the basis for deciding whether privacy protection is worth pursuing. It’s like saying *“some vegetarians are hypocritical, therefore vegetarianism for environmental reasons is meaningless”*—the logic simply doesn’t hold. Or like concluding *“grapes are better than apples because one box of apples has a rotten one while a box of grapes doesn’t.”* But I digress. Let’s return to privacy protection.



The phrase *“I have nothing to hide”* is often used to dismiss concerns about privacy. But the legitimacy of privacy protection does not rest on the idea of “hiding information.” At its core, the most fundamental value of privacy, in the philosophical sense, is the protection of human autonomy. By definition, privacy arises from the boundary between the public and the personal sphere. In the public sphere, people’s actions are assumed to be subject to scrutiny, whether based on law or morality. In the personal sphere, however, we expect freedom from the constant “gaze.” This grants us the right to decide without being judged—especially by the tribunal of social morality.



Surveillance as a mechanism erodes this boundary. When we know all our actions are “watched and subject to judgment,” fear prevents us from making choices that truly follow our inner will. In such an environment, democracy becomes impossible, because individual choice loses its foundation. Even if no law requires you to disclose everything, in a world without privacy protection, “not disclosing” is equated with “hiding something,” and “hiding something” equates to “violating social norms.” Merely being “different” becomes grounds for punishment. For example, during the Cultural Revolution in China, no law mandated that every speech must begin with quoting Chairman Mao. But if one failed to do so, it was treated as betraying the Communist cause—a crime punishable in itself. The terrifying part of a society bound by rigid moral codes is how oversimplified equations (*different = wrong; noncompliance = betrayal*) provide justification for any punishment.



Beyond such misunderstandings, another dangerous phenomenon is *“privacy for privacy’s sake.”* David Evans captured this well in his talk *“The Dragon in the Room.”* Over the past decade, privacy regulations have indeed restricted third-party companies from buying user data from big tech corporations. Yet these laws focus on data circulation, not data collection. This shift places companies like Google and Apple at the center of power, with near-absolute control.



The original intention of privacy-preserving technologies was to prevent governments or corporations from gaining so much data that they could manipulate users. Technology was only the means; the end was the preservation of autonomy. But today, big tech companies recruit privacy researchers with high salaries and showcase their use of privacy-preserving technologies to regulators: *“we use blabla privacy-preserving techniques, we comply with XXX privacy law, and collecting this data is essential for product improvement.”* The information asymmetry produces power asymmetry. Individuals, already disadvantaged compared to corporations, lose even more ground once they hand over their data. Existing privacy laws, in this context, lose their “teeth”—they cannot truly protect users. Corporations even exploit linguistic loopholes to maintain full control. In this way, privacy-preserving technologies, once a shield for autonomy, risk becoming a weapon in the hands of the very adversaries they were meant to restrain.



In addressing the questions of *what, why, and how*, engineers can often only answer the first—the easiest. As researchers, when we focus too much on *“How can I do this?”* while neglecting *“Why am I doing this?”*, perhaps it already signals that we are ceding important ground.